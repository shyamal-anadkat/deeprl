{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "1_cartpole_a2c.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb0155d6"
      },
      "source": [
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines3[extra]"
      ],
      "id": "fb0155d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZJbepAOBBR4"
      },
      "source": [
        "pip install git+https://github.com/shyamal-anadkat/stable-baselines3"
      ],
      "id": "SZJbepAOBBR4",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phDiQLBcHUHA"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "id": "phDiQLBcHUHA",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBrHdzFyHZ5y",
        "outputId": "8396285a-ced7-43b9-be0d-2d5cddcd4684"
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=\"./a2c_cartpole_tensorboard/\")\n"
      ],
      "id": "RBrHdzFyHZ5y",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyBMq0yVFh79",
        "outputId": "6fcccd3b-9885-4b86-c126-5d8786582d76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Use a separate environement for evaluation\n",
        "eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "# Random Agent, before training\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "id": "OyBMq0yVFh79",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/stable-baselines3/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:91.00 +/- 53.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZMXxE33Fidc",
        "outputId": "528c8bde-c709-461f-963b-1252d417bce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the agent for 10000 steps\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "id": "uZMXxE33Fidc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./a2c_cartpole_tensorboard/A2C_1\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.5     |\n",
            "|    ep_rew_mean        | 43.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.645   |\n",
            "|    explained_variance | -0.332   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 1.73     |\n",
            "|    value_loss         | 12.1     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.5     |\n",
            "|    ep_rew_mean        | 41.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 315      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.642   |\n",
            "|    explained_variance | 0.0961   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 1.32     |\n",
            "|    value_loss         | 7.1      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.4     |\n",
            "|    ep_rew_mean        | 43.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 388      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.654   |\n",
            "|    explained_variance | 0.166    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.48     |\n",
            "|    value_loss         | 5.89     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41       |\n",
            "|    ep_rew_mean        | 41       |\n",
            "| time/                 |          |\n",
            "|    fps                | 441      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.67    |\n",
            "|    explained_variance | -0.0376  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.39     |\n",
            "|    value_loss         | 5.91     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 45.5     |\n",
            "|    ep_rew_mean        | 45.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 479      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.651   |\n",
            "|    explained_variance | -0.021   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.07     |\n",
            "|    value_loss         | 5.21     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 48.3     |\n",
            "|    ep_rew_mean        | 48.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 507      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.647   |\n",
            "|    explained_variance | -0.0057  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.962    |\n",
            "|    value_loss         | 4.54     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 51.8     |\n",
            "|    ep_rew_mean        | 51.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 529      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.566   |\n",
            "|    explained_variance | 0.00239  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.08     |\n",
            "|    value_loss         | 4.05     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 53.5     |\n",
            "|    ep_rew_mean        | 53.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 547      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.609   |\n",
            "|    explained_variance | -0.0026  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.849    |\n",
            "|    value_loss         | 3.54     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 57.1      |\n",
            "|    ep_rew_mean        | 57.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 563       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.605    |\n",
            "|    explained_variance | -0.000983 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 0.706     |\n",
            "|    value_loss         | 3.04      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 59.2      |\n",
            "|    ep_rew_mean        | 59.2      |\n",
            "| time/                 |           |\n",
            "|    fps                | 576       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.529    |\n",
            "|    explained_variance | -0.000865 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 0.681     |\n",
            "|    value_loss         | 2.56      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 66.1      |\n",
            "|    ep_rew_mean        | 66.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 586       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.484    |\n",
            "|    explained_variance | -0.000274 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.874     |\n",
            "|    value_loss         | 2.13      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 69.2     |\n",
            "|    ep_rew_mean        | 69.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 595      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.474   |\n",
            "|    explained_variance | -0.00174 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.456    |\n",
            "|    value_loss         | 1.74     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 73.7      |\n",
            "|    ep_rew_mean        | 73.7      |\n",
            "| time/                 |           |\n",
            "|    fps                | 603       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.581    |\n",
            "|    explained_variance | -0.000259 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.443     |\n",
            "|    value_loss         | 1.38      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 77.6      |\n",
            "|    ep_rew_mean        | 77.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.524    |\n",
            "|    explained_variance | -9.67e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 0.469     |\n",
            "|    value_loss         | 1.06      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 80.6      |\n",
            "|    ep_rew_mean        | 80.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.484    |\n",
            "|    explained_variance | -1.78e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.29      |\n",
            "|    value_loss         | 0.796     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 82.5      |\n",
            "|    ep_rew_mean        | 82.5      |\n",
            "| time/                 |           |\n",
            "|    fps                | 621       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.476    |\n",
            "|    explained_variance | -6.82e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 0.162     |\n",
            "|    value_loss         | 0.571     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 85.5     |\n",
            "|    ep_rew_mean        | 85.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 626      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.36    |\n",
            "|    explained_variance | 2.5e-05  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.328    |\n",
            "|    value_loss         | 0.376    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 89.3     |\n",
            "|    ep_rew_mean        | 89.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 630      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.363   |\n",
            "|    explained_variance | 6.56e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.092    |\n",
            "|    value_loss         | 0.222    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 92.3      |\n",
            "|    ep_rew_mean        | 92.3      |\n",
            "| time/                 |           |\n",
            "|    fps                | 634       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.319    |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 0.203     |\n",
            "|    value_loss         | 0.109     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 96.1     |\n",
            "|    ep_rew_mean        | 96.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 637      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.423   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0696   |\n",
            "|    value_loss         | 0.0355   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/stable-baselines3/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:287.51 +/- 36.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XIdm8v6Fq5C"
      },
      "source": [
        ""
      ],
      "id": "7XIdm8v6Fq5C",
      "execution_count": null,
      "outputs": []
    }
  ]
}